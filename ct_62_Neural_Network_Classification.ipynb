{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ct 62 Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunbairagi/Machine-Learning-CT62/blob/main/ct_62_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "CO CST IMPLEMENTATION OF NEURAL NETWORK\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771d95ed-d510-47ae-ae4d-4b7a0dccff49"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "908fbc19-9d7d-4d5f-ed16-463990e5c910"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f497049-92ce-4cee-8be1-57819b213b3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0827CT191062.docx\n",
            " 0827CT191062_linuxlab.pdf\n",
            "'alexa decription.pdf'\n",
            " Classroom\n",
            "'codechef varunCT62.pdf'\n",
            "'Colab Notebooks'\n",
            "'CST-3rd year V sem DBMS CST'\n",
            " custom_trainvalacc.png\n",
            " custom_trainvalloss.png\n",
            "'cyber assignment CT62.pdf'\n",
            " diabetes.csv\n",
            " Document\n",
            "'Document from Varun Bairagi'\n",
            " DriveAce\n",
            " DriveApp\n",
            " DrivePro\n",
            " GDToT\n",
            "'Getting started.pdf'\n",
            " images\n",
            " IMG-20210811-WA0002.jpg\n",
            "'IMG_20211217_220848 (1).jpg'\n",
            " IMG_20211217_220848.jpg\n",
            "'Iwt assignment'\n",
            " laptops.csv.gsheet\n",
            " let-us-c-plus-plus-yashwant-kanetkar.pdf\n",
            "'Linux lab work'\n",
            " Logistic_Regression_Scratch.ipynb\n",
            "'machine learning'\n",
            " MicrosoftCertificate.pdf\n",
            " modify_zero.origin\n",
            " movies\n",
            "'MST-1_Data Structure Quiz CT.csv.gsheet'\n",
            "'online lecture-ADA'\n",
            " petrol_consumption.csv\n",
            "'prathvi project'\n",
            " Project\n",
            " project1\n",
            " python_70_qus_assig_CT62_varun\n",
            " Screenshot_2021-09-15-12-10-48-883_com.google.android.youtube.jpg\n",
            " Screenshot_20211004-174653.png\n",
            " Screenshot_2022-03-08-10-41-35-748_com.android.chrome.jpg\n",
            " ShareGDrive\n",
            "'TOC Lab Ass 4 ct62.docx'\n",
            "'Varun Bairagi 0827CT191062.docx'\n",
            "'varun bairagi assignment.docx'\n",
            "'Varun Bairagi CT62.pdf'\n",
            "'varun bairagi digital system lab (1).pdf'\n",
            " voiceflow-export-1640777811121.png\n",
            "'voiceflow-export-1640777825174 (1).pdf'\n",
            " zero.origin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "32nNonRSSaQq",
        "outputId": "1319c793-6412-4c7d-b922-e9089fd3868f"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-188e9d62-892e-485d-a4f7-3d64ae35f713\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-188e9d62-892e-485d-a4f7-3d64ae35f713')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-188e9d62-892e-485d-a4f7-3d64ae35f713 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-188e9d62-892e-485d-a4f7-3d64ae35f713');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "41b6bf48-4cc7-4ed6-d9c4-7983f06293e3"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "671ecd07-2f97-4913-c9bf-ff7c58fed56d"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "817f905b-72cb-4d9e-91a5-4afdc142e0aa"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "8a556eaf-13ab-477a-8168-ae234478c4f1"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "38eb0175-31e9-4665-c87c-e93c1187e079"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "6efbf50f-2b47-4f4d-9941-056fa1466111"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.4, random_state=15)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.7, random_state=20)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138\n",
            "308\n",
            "322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06de9a38-e60b-41cc-fd30-d539acf6a7a7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(25, activation='relu'))\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 25)                525       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 12)                312       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,043\n",
            "Trainable params: 1,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "06a3220f-8c10-4118-d270-4e4125a9acd3"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=6,  epochs=400, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "23/23 [==============================] - 1s 12ms/step - loss: 0.7049 - accuracy: 0.5290 - val_loss: 0.6836 - val_accuracy: 0.6149\n",
            "Epoch 2/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7030 - accuracy: 0.5652 - val_loss: 0.6810 - val_accuracy: 0.6273\n",
            "Epoch 3/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.5580 - val_loss: 0.6788 - val_accuracy: 0.6335\n",
            "Epoch 4/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6994 - accuracy: 0.5580 - val_loss: 0.6769 - val_accuracy: 0.6429\n",
            "Epoch 5/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5652 - val_loss: 0.6751 - val_accuracy: 0.6491\n",
            "Epoch 6/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5797 - val_loss: 0.6736 - val_accuracy: 0.6460\n",
            "Epoch 7/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.5870 - val_loss: 0.6722 - val_accuracy: 0.6522\n",
            "Epoch 8/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5870 - val_loss: 0.6709 - val_accuracy: 0.6491\n",
            "Epoch 9/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6014 - val_loss: 0.6699 - val_accuracy: 0.6429\n",
            "Epoch 10/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6921 - accuracy: 0.6014 - val_loss: 0.6689 - val_accuracy: 0.6398\n",
            "Epoch 11/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.6014 - val_loss: 0.6681 - val_accuracy: 0.6429\n",
            "Epoch 12/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.6014 - val_loss: 0.6672 - val_accuracy: 0.6429\n",
            "Epoch 13/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.6087 - val_loss: 0.6664 - val_accuracy: 0.6429\n",
            "Epoch 14/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.6087 - val_loss: 0.6656 - val_accuracy: 0.6429\n",
            "Epoch 15/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.6087 - val_loss: 0.6648 - val_accuracy: 0.6429\n",
            "Epoch 16/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.6087 - val_loss: 0.6642 - val_accuracy: 0.6429\n",
            "Epoch 17/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6865 - accuracy: 0.6087 - val_loss: 0.6634 - val_accuracy: 0.6429\n",
            "Epoch 18/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.6014 - val_loss: 0.6628 - val_accuracy: 0.6429\n",
            "Epoch 19/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6849 - accuracy: 0.6014 - val_loss: 0.6621 - val_accuracy: 0.6429\n",
            "Epoch 20/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6840 - accuracy: 0.6014 - val_loss: 0.6614 - val_accuracy: 0.6429\n",
            "Epoch 21/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.6014 - val_loss: 0.6608 - val_accuracy: 0.6429\n",
            "Epoch 22/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.6014 - val_loss: 0.6601 - val_accuracy: 0.6429\n",
            "Epoch 23/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6818 - accuracy: 0.6014 - val_loss: 0.6595 - val_accuracy: 0.6429\n",
            "Epoch 24/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.6014 - val_loss: 0.6589 - val_accuracy: 0.6429\n",
            "Epoch 25/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.6014 - val_loss: 0.6584 - val_accuracy: 0.6429\n",
            "Epoch 26/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.6014 - val_loss: 0.6578 - val_accuracy: 0.6429\n",
            "Epoch 27/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.6014 - val_loss: 0.6572 - val_accuracy: 0.6429\n",
            "Epoch 28/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6781 - accuracy: 0.6014 - val_loss: 0.6566 - val_accuracy: 0.6429\n",
            "Epoch 29/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.6087 - val_loss: 0.6561 - val_accuracy: 0.6429\n",
            "Epoch 30/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.6014 - val_loss: 0.6556 - val_accuracy: 0.6429\n",
            "Epoch 31/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.6014 - val_loss: 0.6551 - val_accuracy: 0.6429\n",
            "Epoch 32/400\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6755 - accuracy: 0.6014 - val_loss: 0.6545 - val_accuracy: 0.6429\n",
            "Epoch 33/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6745 - accuracy: 0.6014 - val_loss: 0.6540 - val_accuracy: 0.6429\n",
            "Epoch 34/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6739 - accuracy: 0.6014 - val_loss: 0.6535 - val_accuracy: 0.6429\n",
            "Epoch 35/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.6014 - val_loss: 0.6530 - val_accuracy: 0.6429\n",
            "Epoch 36/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6726 - accuracy: 0.6014 - val_loss: 0.6524 - val_accuracy: 0.6429\n",
            "Epoch 37/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.6014 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
            "Epoch 38/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6716 - accuracy: 0.6014 - val_loss: 0.6515 - val_accuracy: 0.6429\n",
            "Epoch 39/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6014 - val_loss: 0.6510 - val_accuracy: 0.6429\n",
            "Epoch 40/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6701 - accuracy: 0.6014 - val_loss: 0.6505 - val_accuracy: 0.6429\n",
            "Epoch 41/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6696 - accuracy: 0.6014 - val_loss: 0.6501 - val_accuracy: 0.6429\n",
            "Epoch 42/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.6014 - val_loss: 0.6495 - val_accuracy: 0.6429\n",
            "Epoch 43/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.6014 - val_loss: 0.6490 - val_accuracy: 0.6429\n",
            "Epoch 44/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.6014 - val_loss: 0.6485 - val_accuracy: 0.6429\n",
            "Epoch 45/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.6014 - val_loss: 0.6480 - val_accuracy: 0.6429\n",
            "Epoch 46/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6664 - accuracy: 0.6014 - val_loss: 0.6475 - val_accuracy: 0.6429\n",
            "Epoch 47/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6014 - val_loss: 0.6471 - val_accuracy: 0.6429\n",
            "Epoch 48/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.6014 - val_loss: 0.6467 - val_accuracy: 0.6429\n",
            "Epoch 49/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6649 - accuracy: 0.6014 - val_loss: 0.6462 - val_accuracy: 0.6429\n",
            "Epoch 50/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.6014 - val_loss: 0.6457 - val_accuracy: 0.6429\n",
            "Epoch 51/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.6014 - val_loss: 0.6452 - val_accuracy: 0.6429\n",
            "Epoch 52/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.6014 - val_loss: 0.6448 - val_accuracy: 0.6429\n",
            "Epoch 53/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6014 - val_loss: 0.6443 - val_accuracy: 0.6429\n",
            "Epoch 54/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6623 - accuracy: 0.6014 - val_loss: 0.6439 - val_accuracy: 0.6429\n",
            "Epoch 55/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.6014 - val_loss: 0.6435 - val_accuracy: 0.6429\n",
            "Epoch 56/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6610 - accuracy: 0.6014 - val_loss: 0.6430 - val_accuracy: 0.6429\n",
            "Epoch 57/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.6014 - val_loss: 0.6426 - val_accuracy: 0.6429\n",
            "Epoch 58/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.6014 - val_loss: 0.6421 - val_accuracy: 0.6429\n",
            "Epoch 59/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6596 - accuracy: 0.6014 - val_loss: 0.6418 - val_accuracy: 0.6429\n",
            "Epoch 60/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6591 - accuracy: 0.6014 - val_loss: 0.6415 - val_accuracy: 0.6429\n",
            "Epoch 61/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6584 - accuracy: 0.6014 - val_loss: 0.6410 - val_accuracy: 0.6429\n",
            "Epoch 62/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6579 - accuracy: 0.6014 - val_loss: 0.6405 - val_accuracy: 0.6429\n",
            "Epoch 63/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.6014 - val_loss: 0.6401 - val_accuracy: 0.6429\n",
            "Epoch 64/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.6014 - val_loss: 0.6397 - val_accuracy: 0.6429\n",
            "Epoch 65/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.6014 - val_loss: 0.6393 - val_accuracy: 0.6429\n",
            "Epoch 66/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6562 - accuracy: 0.6014 - val_loss: 0.6388 - val_accuracy: 0.6429\n",
            "Epoch 67/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.6014 - val_loss: 0.6384 - val_accuracy: 0.6429\n",
            "Epoch 68/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6551 - accuracy: 0.6014 - val_loss: 0.6380 - val_accuracy: 0.6429\n",
            "Epoch 69/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6014 - val_loss: 0.6375 - val_accuracy: 0.6429\n",
            "Epoch 70/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6014 - val_loss: 0.6371 - val_accuracy: 0.6429\n",
            "Epoch 71/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6536 - accuracy: 0.6014 - val_loss: 0.6367 - val_accuracy: 0.6429\n",
            "Epoch 72/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.6014 - val_loss: 0.6362 - val_accuracy: 0.6429\n",
            "Epoch 73/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6014 - val_loss: 0.6358 - val_accuracy: 0.6429\n",
            "Epoch 74/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.6014 - val_loss: 0.6354 - val_accuracy: 0.6429\n",
            "Epoch 75/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.6014 - val_loss: 0.6350 - val_accuracy: 0.6429\n",
            "Epoch 76/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6513 - accuracy: 0.6014 - val_loss: 0.6346 - val_accuracy: 0.6429\n",
            "Epoch 77/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6511 - accuracy: 0.6014 - val_loss: 0.6342 - val_accuracy: 0.6429\n",
            "Epoch 78/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6503 - accuracy: 0.6014 - val_loss: 0.6338 - val_accuracy: 0.6398\n",
            "Epoch 79/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6503 - accuracy: 0.6014 - val_loss: 0.6334 - val_accuracy: 0.6398\n",
            "Epoch 80/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6494 - accuracy: 0.6014 - val_loss: 0.6330 - val_accuracy: 0.6429\n",
            "Epoch 81/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6490 - accuracy: 0.6014 - val_loss: 0.6327 - val_accuracy: 0.6429\n",
            "Epoch 82/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6486 - accuracy: 0.6014 - val_loss: 0.6323 - val_accuracy: 0.6429\n",
            "Epoch 83/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6087 - val_loss: 0.6318 - val_accuracy: 0.6429\n",
            "Epoch 84/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6477 - accuracy: 0.6014 - val_loss: 0.6315 - val_accuracy: 0.6429\n",
            "Epoch 85/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6473 - accuracy: 0.6087 - val_loss: 0.6311 - val_accuracy: 0.6429\n",
            "Epoch 86/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6087 - val_loss: 0.6307 - val_accuracy: 0.6429\n",
            "Epoch 87/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6465 - accuracy: 0.6087 - val_loss: 0.6303 - val_accuracy: 0.6429\n",
            "Epoch 88/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6457 - accuracy: 0.6087 - val_loss: 0.6299 - val_accuracy: 0.6460\n",
            "Epoch 89/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6014 - val_loss: 0.6295 - val_accuracy: 0.6460\n",
            "Epoch 90/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6449 - accuracy: 0.6087 - val_loss: 0.6291 - val_accuracy: 0.6491\n",
            "Epoch 91/400\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.6014 - val_loss: 0.6286 - val_accuracy: 0.6491\n",
            "Epoch 92/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6438 - accuracy: 0.6087 - val_loss: 0.6282 - val_accuracy: 0.6491\n",
            "Epoch 93/400\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.6433 - accuracy: 0.6014 - val_loss: 0.6278 - val_accuracy: 0.6491\n",
            "Epoch 94/400\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.6431 - accuracy: 0.6014 - val_loss: 0.6274 - val_accuracy: 0.6491\n",
            "Epoch 95/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6426 - accuracy: 0.6014 - val_loss: 0.6269 - val_accuracy: 0.6491\n",
            "Epoch 96/400\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.6420 - accuracy: 0.6014 - val_loss: 0.6266 - val_accuracy: 0.6491\n",
            "Epoch 97/400\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.6420 - accuracy: 0.6087 - val_loss: 0.6262 - val_accuracy: 0.6491\n",
            "Epoch 98/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.6014 - val_loss: 0.6258 - val_accuracy: 0.6491\n",
            "Epoch 99/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6410 - accuracy: 0.6087 - val_loss: 0.6253 - val_accuracy: 0.6491\n",
            "Epoch 100/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6087 - val_loss: 0.6250 - val_accuracy: 0.6522\n",
            "Epoch 101/400\n",
            "23/23 [==============================] - 0s 22ms/step - loss: 0.6398 - accuracy: 0.6087 - val_loss: 0.6245 - val_accuracy: 0.6491\n",
            "Epoch 102/400\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.6393 - accuracy: 0.6087 - val_loss: 0.6242 - val_accuracy: 0.6491\n",
            "Epoch 103/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6087 - val_loss: 0.6239 - val_accuracy: 0.6553\n",
            "Epoch 104/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6087 - val_loss: 0.6235 - val_accuracy: 0.6584\n",
            "Epoch 105/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6378 - accuracy: 0.6087 - val_loss: 0.6231 - val_accuracy: 0.6584\n",
            "Epoch 106/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6087 - val_loss: 0.6227 - val_accuracy: 0.6584\n",
            "Epoch 107/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6369 - accuracy: 0.6087 - val_loss: 0.6223 - val_accuracy: 0.6584\n",
            "Epoch 108/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6364 - accuracy: 0.6159 - val_loss: 0.6219 - val_accuracy: 0.6584\n",
            "Epoch 109/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6362 - accuracy: 0.6087 - val_loss: 0.6215 - val_accuracy: 0.6584\n",
            "Epoch 110/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6357 - accuracy: 0.6087 - val_loss: 0.6211 - val_accuracy: 0.6553\n",
            "Epoch 111/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.6159 - val_loss: 0.6206 - val_accuracy: 0.6553\n",
            "Epoch 112/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6349 - accuracy: 0.6159 - val_loss: 0.6202 - val_accuracy: 0.6553\n",
            "Epoch 113/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6159 - val_loss: 0.6198 - val_accuracy: 0.6553\n",
            "Epoch 114/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6342 - accuracy: 0.6159 - val_loss: 0.6194 - val_accuracy: 0.6553\n",
            "Epoch 115/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6334 - accuracy: 0.6159 - val_loss: 0.6190 - val_accuracy: 0.6553\n",
            "Epoch 116/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.6159 - val_loss: 0.6185 - val_accuracy: 0.6553\n",
            "Epoch 117/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.6159 - val_loss: 0.6181 - val_accuracy: 0.6553\n",
            "Epoch 118/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6324 - accuracy: 0.6159 - val_loss: 0.6178 - val_accuracy: 0.6553\n",
            "Epoch 119/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6159 - val_loss: 0.6174 - val_accuracy: 0.6584\n",
            "Epoch 120/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6159 - val_loss: 0.6170 - val_accuracy: 0.6553\n",
            "Epoch 121/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6305 - accuracy: 0.6159 - val_loss: 0.6166 - val_accuracy: 0.6553\n",
            "Epoch 122/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6306 - accuracy: 0.6159 - val_loss: 0.6162 - val_accuracy: 0.6553\n",
            "Epoch 123/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6232 - val_loss: 0.6158 - val_accuracy: 0.6553\n",
            "Epoch 124/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.6159 - val_loss: 0.6153 - val_accuracy: 0.6553\n",
            "Epoch 125/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6290 - accuracy: 0.6159 - val_loss: 0.6150 - val_accuracy: 0.6553\n",
            "Epoch 126/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.6232 - val_loss: 0.6146 - val_accuracy: 0.6553\n",
            "Epoch 127/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6279 - accuracy: 0.6232 - val_loss: 0.6142 - val_accuracy: 0.6615\n",
            "Epoch 128/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6278 - accuracy: 0.6232 - val_loss: 0.6138 - val_accuracy: 0.6646\n",
            "Epoch 129/400\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6273 - accuracy: 0.6159 - val_loss: 0.6134 - val_accuracy: 0.6677\n",
            "Epoch 130/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.6159 - val_loss: 0.6130 - val_accuracy: 0.6646\n",
            "Epoch 131/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6232 - val_loss: 0.6126 - val_accuracy: 0.6646\n",
            "Epoch 132/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.6232 - val_loss: 0.6123 - val_accuracy: 0.6646\n",
            "Epoch 133/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6159 - val_loss: 0.6119 - val_accuracy: 0.6646\n",
            "Epoch 134/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6252 - accuracy: 0.6232 - val_loss: 0.6117 - val_accuracy: 0.6646\n",
            "Epoch 135/400\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.6232 - val_loss: 0.6112 - val_accuracy: 0.6646\n",
            "Epoch 136/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.6232 - val_loss: 0.6107 - val_accuracy: 0.6646\n",
            "Epoch 137/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6236 - accuracy: 0.6232 - val_loss: 0.6104 - val_accuracy: 0.6677\n",
            "Epoch 138/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6234 - accuracy: 0.6232 - val_loss: 0.6100 - val_accuracy: 0.6708\n",
            "Epoch 139/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6227 - accuracy: 0.6232 - val_loss: 0.6096 - val_accuracy: 0.6739\n",
            "Epoch 140/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.6159 - val_loss: 0.6092 - val_accuracy: 0.6739\n",
            "Epoch 141/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.6304 - val_loss: 0.6088 - val_accuracy: 0.6739\n",
            "Epoch 142/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6232 - val_loss: 0.6084 - val_accuracy: 0.6770\n",
            "Epoch 143/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6232 - val_loss: 0.6081 - val_accuracy: 0.6739\n",
            "Epoch 144/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6206 - accuracy: 0.6304 - val_loss: 0.6077 - val_accuracy: 0.6739\n",
            "Epoch 145/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.6304 - val_loss: 0.6074 - val_accuracy: 0.6770\n",
            "Epoch 146/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6377 - val_loss: 0.6069 - val_accuracy: 0.6770\n",
            "Epoch 147/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6198 - accuracy: 0.6377 - val_loss: 0.6065 - val_accuracy: 0.6801\n",
            "Epoch 148/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6192 - accuracy: 0.6449 - val_loss: 0.6060 - val_accuracy: 0.6801\n",
            "Epoch 149/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.6377 - val_loss: 0.6056 - val_accuracy: 0.6832\n",
            "Epoch 150/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.6377 - val_loss: 0.6053 - val_accuracy: 0.6801\n",
            "Epoch 151/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.6522 - val_loss: 0.6048 - val_accuracy: 0.6801\n",
            "Epoch 152/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6449 - val_loss: 0.6045 - val_accuracy: 0.6801\n",
            "Epoch 153/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.6522 - val_loss: 0.6041 - val_accuracy: 0.6770\n",
            "Epoch 154/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.6377 - val_loss: 0.6037 - val_accuracy: 0.6801\n",
            "Epoch 155/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.6377 - val_loss: 0.6033 - val_accuracy: 0.6801\n",
            "Epoch 156/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.6522 - val_loss: 0.6029 - val_accuracy: 0.6801\n",
            "Epoch 157/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.6522 - val_loss: 0.6025 - val_accuracy: 0.6801\n",
            "Epoch 158/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.6449 - val_loss: 0.6022 - val_accuracy: 0.6832\n",
            "Epoch 159/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6143 - accuracy: 0.6522 - val_loss: 0.6019 - val_accuracy: 0.6832\n",
            "Epoch 160/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6138 - accuracy: 0.6377 - val_loss: 0.6014 - val_accuracy: 0.6832\n",
            "Epoch 161/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.6449 - val_loss: 0.6010 - val_accuracy: 0.6832\n",
            "Epoch 162/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6129 - accuracy: 0.6522 - val_loss: 0.6006 - val_accuracy: 0.6832\n",
            "Epoch 163/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.6449 - val_loss: 0.6003 - val_accuracy: 0.6832\n",
            "Epoch 164/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.6594 - val_loss: 0.5999 - val_accuracy: 0.6801\n",
            "Epoch 165/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.6594 - val_loss: 0.5995 - val_accuracy: 0.6801\n",
            "Epoch 166/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.6449 - val_loss: 0.5991 - val_accuracy: 0.6832\n",
            "Epoch 167/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6108 - accuracy: 0.6522 - val_loss: 0.5987 - val_accuracy: 0.6832\n",
            "Epoch 168/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.6449 - val_loss: 0.5983 - val_accuracy: 0.6832\n",
            "Epoch 169/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.6449 - val_loss: 0.5980 - val_accuracy: 0.6894\n",
            "Epoch 170/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.6522 - val_loss: 0.5976 - val_accuracy: 0.6894\n",
            "Epoch 171/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.6594 - val_loss: 0.5973 - val_accuracy: 0.6894\n",
            "Epoch 172/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6087 - accuracy: 0.6449 - val_loss: 0.5969 - val_accuracy: 0.6863\n",
            "Epoch 173/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.6522 - val_loss: 0.5965 - val_accuracy: 0.6832\n",
            "Epoch 174/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6081 - accuracy: 0.6522 - val_loss: 0.5962 - val_accuracy: 0.6832\n",
            "Epoch 175/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6667 - val_loss: 0.5958 - val_accuracy: 0.6832\n",
            "Epoch 176/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6739 - val_loss: 0.5954 - val_accuracy: 0.6832\n",
            "Epoch 177/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6067 - accuracy: 0.6667 - val_loss: 0.5951 - val_accuracy: 0.6832\n",
            "Epoch 178/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6065 - accuracy: 0.6667 - val_loss: 0.5946 - val_accuracy: 0.6832\n",
            "Epoch 179/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6055 - accuracy: 0.6594 - val_loss: 0.5942 - val_accuracy: 0.6832\n",
            "Epoch 180/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6739 - val_loss: 0.5938 - val_accuracy: 0.6832\n",
            "Epoch 181/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.6739 - val_loss: 0.5933 - val_accuracy: 0.6832\n",
            "Epoch 182/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6045 - accuracy: 0.6667 - val_loss: 0.5929 - val_accuracy: 0.6832\n",
            "Epoch 183/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6041 - accuracy: 0.6884 - val_loss: 0.5924 - val_accuracy: 0.6832\n",
            "Epoch 184/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.6667 - val_loss: 0.5922 - val_accuracy: 0.6832\n",
            "Epoch 185/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.6667 - val_loss: 0.5919 - val_accuracy: 0.6832\n",
            "Epoch 186/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6028 - accuracy: 0.6739 - val_loss: 0.5915 - val_accuracy: 0.6863\n",
            "Epoch 187/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6024 - accuracy: 0.6594 - val_loss: 0.5913 - val_accuracy: 0.6894\n",
            "Epoch 188/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6019 - accuracy: 0.6812 - val_loss: 0.5909 - val_accuracy: 0.6894\n",
            "Epoch 189/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.6884 - val_loss: 0.5905 - val_accuracy: 0.6894\n",
            "Epoch 190/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.6957 - val_loss: 0.5900 - val_accuracy: 0.6925\n",
            "Epoch 191/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6011 - accuracy: 0.6957 - val_loss: 0.5897 - val_accuracy: 0.6925\n",
            "Epoch 192/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.6884 - val_loss: 0.5894 - val_accuracy: 0.6925\n",
            "Epoch 193/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6000 - accuracy: 0.7101 - val_loss: 0.5890 - val_accuracy: 0.6925\n",
            "Epoch 194/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.6957 - val_loss: 0.5886 - val_accuracy: 0.6925\n",
            "Epoch 195/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5992 - accuracy: 0.6884 - val_loss: 0.5883 - val_accuracy: 0.6894\n",
            "Epoch 196/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5988 - accuracy: 0.7029 - val_loss: 0.5878 - val_accuracy: 0.6894\n",
            "Epoch 197/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5981 - accuracy: 0.7101 - val_loss: 0.5874 - val_accuracy: 0.6894\n",
            "Epoch 198/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.6957 - val_loss: 0.5871 - val_accuracy: 0.6957\n",
            "Epoch 199/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.7174 - val_loss: 0.5867 - val_accuracy: 0.6957\n",
            "Epoch 200/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.7101 - val_loss: 0.5862 - val_accuracy: 0.6957\n",
            "Epoch 201/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5966 - accuracy: 0.6957 - val_loss: 0.5860 - val_accuracy: 0.6957\n",
            "Epoch 202/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.7101 - val_loss: 0.5856 - val_accuracy: 0.6925\n",
            "Epoch 203/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7101 - val_loss: 0.5851 - val_accuracy: 0.6957\n",
            "Epoch 204/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5957 - accuracy: 0.7246 - val_loss: 0.5849 - val_accuracy: 0.6957\n",
            "Epoch 205/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5950 - accuracy: 0.7101 - val_loss: 0.5845 - val_accuracy: 0.6957\n",
            "Epoch 206/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.7101 - val_loss: 0.5841 - val_accuracy: 0.6957\n",
            "Epoch 207/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.7101 - val_loss: 0.5837 - val_accuracy: 0.6957\n",
            "Epoch 208/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5941 - accuracy: 0.7174 - val_loss: 0.5832 - val_accuracy: 0.6957\n",
            "Epoch 209/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7101 - val_loss: 0.5829 - val_accuracy: 0.6957\n",
            "Epoch 210/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.7101 - val_loss: 0.5826 - val_accuracy: 0.7019\n",
            "Epoch 211/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.7101 - val_loss: 0.5823 - val_accuracy: 0.7019\n",
            "Epoch 212/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.7101 - val_loss: 0.5819 - val_accuracy: 0.7019\n",
            "Epoch 213/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7101 - val_loss: 0.5815 - val_accuracy: 0.7050\n",
            "Epoch 214/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5915 - accuracy: 0.7101 - val_loss: 0.5810 - val_accuracy: 0.7050\n",
            "Epoch 215/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.7101 - val_loss: 0.5806 - val_accuracy: 0.7050\n",
            "Epoch 216/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5908 - accuracy: 0.7029 - val_loss: 0.5803 - val_accuracy: 0.7050\n",
            "Epoch 217/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.7174 - val_loss: 0.5798 - val_accuracy: 0.7050\n",
            "Epoch 218/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7174 - val_loss: 0.5795 - val_accuracy: 0.7050\n",
            "Epoch 219/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5895 - accuracy: 0.7029 - val_loss: 0.5791 - val_accuracy: 0.7081\n",
            "Epoch 220/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5896 - accuracy: 0.7101 - val_loss: 0.5788 - val_accuracy: 0.7019\n",
            "Epoch 221/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.7174 - val_loss: 0.5784 - val_accuracy: 0.7019\n",
            "Epoch 222/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.7174 - val_loss: 0.5780 - val_accuracy: 0.7019\n",
            "Epoch 223/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.7174 - val_loss: 0.5776 - val_accuracy: 0.7019\n",
            "Epoch 224/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.7174 - val_loss: 0.5773 - val_accuracy: 0.7019\n",
            "Epoch 225/400\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5874 - accuracy: 0.7174 - val_loss: 0.5769 - val_accuracy: 0.7019\n",
            "Epoch 226/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.7174 - val_loss: 0.5766 - val_accuracy: 0.7019\n",
            "Epoch 227/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7174 - val_loss: 0.5762 - val_accuracy: 0.7050\n",
            "Epoch 228/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5862 - accuracy: 0.7174 - val_loss: 0.5758 - val_accuracy: 0.7050\n",
            "Epoch 229/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5853 - accuracy: 0.7101 - val_loss: 0.5755 - val_accuracy: 0.7112\n",
            "Epoch 230/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.7174 - val_loss: 0.5751 - val_accuracy: 0.7112\n",
            "Epoch 231/400\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5846 - accuracy: 0.7174 - val_loss: 0.5746 - val_accuracy: 0.7112\n",
            "Epoch 232/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.7174 - val_loss: 0.5743 - val_accuracy: 0.7112\n",
            "Epoch 233/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7101 - val_loss: 0.5738 - val_accuracy: 0.7112\n",
            "Epoch 234/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5835 - accuracy: 0.7174 - val_loss: 0.5735 - val_accuracy: 0.7112\n",
            "Epoch 235/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.7101 - val_loss: 0.5732 - val_accuracy: 0.7143\n",
            "Epoch 236/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.7101 - val_loss: 0.5728 - val_accuracy: 0.7112\n",
            "Epoch 237/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.7174 - val_loss: 0.5726 - val_accuracy: 0.7112\n",
            "Epoch 238/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.7101 - val_loss: 0.5723 - val_accuracy: 0.7112\n",
            "Epoch 239/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7246 - val_loss: 0.5718 - val_accuracy: 0.7112\n",
            "Epoch 240/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5810 - accuracy: 0.7174 - val_loss: 0.5713 - val_accuracy: 0.7112\n",
            "Epoch 241/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7174 - val_loss: 0.5709 - val_accuracy: 0.7112\n",
            "Epoch 242/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5806 - accuracy: 0.7174 - val_loss: 0.5705 - val_accuracy: 0.7112\n",
            "Epoch 243/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.7174 - val_loss: 0.5702 - val_accuracy: 0.7112\n",
            "Epoch 244/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5793 - accuracy: 0.7174 - val_loss: 0.5698 - val_accuracy: 0.7112\n",
            "Epoch 245/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.7101 - val_loss: 0.5693 - val_accuracy: 0.7112\n",
            "Epoch 246/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.7246 - val_loss: 0.5690 - val_accuracy: 0.7112\n",
            "Epoch 247/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.7174 - val_loss: 0.5688 - val_accuracy: 0.7112\n",
            "Epoch 248/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7246 - val_loss: 0.5684 - val_accuracy: 0.7112\n",
            "Epoch 249/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.7174 - val_loss: 0.5680 - val_accuracy: 0.7112\n",
            "Epoch 250/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7174 - val_loss: 0.5678 - val_accuracy: 0.7112\n",
            "Epoch 251/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.7174 - val_loss: 0.5675 - val_accuracy: 0.7143\n",
            "Epoch 252/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5767 - accuracy: 0.7101 - val_loss: 0.5669 - val_accuracy: 0.7112\n",
            "Epoch 253/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.7174 - val_loss: 0.5665 - val_accuracy: 0.7112\n",
            "Epoch 254/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5761 - accuracy: 0.7174 - val_loss: 0.5662 - val_accuracy: 0.7143\n",
            "Epoch 255/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.7246 - val_loss: 0.5658 - val_accuracy: 0.7143\n",
            "Epoch 256/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.7101 - val_loss: 0.5654 - val_accuracy: 0.7143\n",
            "Epoch 257/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7143\n",
            "Epoch 258/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7174 - val_loss: 0.5647 - val_accuracy: 0.7112\n",
            "Epoch 259/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.7174 - val_loss: 0.5643 - val_accuracy: 0.7112\n",
            "Epoch 260/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.7174 - val_loss: 0.5641 - val_accuracy: 0.7174\n",
            "Epoch 261/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.7101 - val_loss: 0.5636 - val_accuracy: 0.7143\n",
            "Epoch 262/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7246 - val_loss: 0.5632 - val_accuracy: 0.7174\n",
            "Epoch 263/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7101 - val_loss: 0.5628 - val_accuracy: 0.7174\n",
            "Epoch 264/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5722 - accuracy: 0.7174 - val_loss: 0.5625 - val_accuracy: 0.7174\n",
            "Epoch 265/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5719 - accuracy: 0.7101 - val_loss: 0.5622 - val_accuracy: 0.7174\n",
            "Epoch 266/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7101 - val_loss: 0.5618 - val_accuracy: 0.7205\n",
            "Epoch 267/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.7174 - val_loss: 0.5614 - val_accuracy: 0.7205\n",
            "Epoch 268/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7101 - val_loss: 0.5610 - val_accuracy: 0.7205\n",
            "Epoch 269/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5704 - accuracy: 0.7174 - val_loss: 0.5607 - val_accuracy: 0.7205\n",
            "Epoch 270/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7174 - val_loss: 0.5603 - val_accuracy: 0.7205\n",
            "Epoch 271/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7101 - val_loss: 0.5598 - val_accuracy: 0.7205\n",
            "Epoch 272/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7174 - val_loss: 0.5596 - val_accuracy: 0.7174\n",
            "Epoch 273/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7174 - val_loss: 0.5594 - val_accuracy: 0.7236\n",
            "Epoch 274/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7174 - val_loss: 0.5590 - val_accuracy: 0.7236\n",
            "Epoch 275/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7174 - val_loss: 0.5585 - val_accuracy: 0.7205\n",
            "Epoch 276/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5678 - accuracy: 0.7174 - val_loss: 0.5581 - val_accuracy: 0.7205\n",
            "Epoch 277/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7174 - val_loss: 0.5578 - val_accuracy: 0.7236\n",
            "Epoch 278/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7246 - val_loss: 0.5574 - val_accuracy: 0.7236\n",
            "Epoch 279/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5663 - accuracy: 0.7246 - val_loss: 0.5570 - val_accuracy: 0.7236\n",
            "Epoch 280/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7246 - val_loss: 0.5566 - val_accuracy: 0.7236\n",
            "Epoch 281/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7246 - val_loss: 0.5562 - val_accuracy: 0.7236\n",
            "Epoch 282/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7246 - val_loss: 0.5558 - val_accuracy: 0.7236\n",
            "Epoch 283/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5648 - accuracy: 0.7246 - val_loss: 0.5555 - val_accuracy: 0.7236\n",
            "Epoch 284/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.7246 - val_loss: 0.5550 - val_accuracy: 0.7236\n",
            "Epoch 285/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5642 - accuracy: 0.7174 - val_loss: 0.5547 - val_accuracy: 0.7236\n",
            "Epoch 286/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5641 - accuracy: 0.7246 - val_loss: 0.5545 - val_accuracy: 0.7267\n",
            "Epoch 287/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7246 - val_loss: 0.5541 - val_accuracy: 0.7267\n",
            "Epoch 288/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5631 - accuracy: 0.7246 - val_loss: 0.5535 - val_accuracy: 0.7267\n",
            "Epoch 289/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7246 - val_loss: 0.5534 - val_accuracy: 0.7298\n",
            "Epoch 290/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7319 - val_loss: 0.5532 - val_accuracy: 0.7360\n",
            "Epoch 291/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5623 - accuracy: 0.7246 - val_loss: 0.5527 - val_accuracy: 0.7298\n",
            "Epoch 292/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7246 - val_loss: 0.5524 - val_accuracy: 0.7360\n",
            "Epoch 293/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.7246 - val_loss: 0.5521 - val_accuracy: 0.7360\n",
            "Epoch 294/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5610 - accuracy: 0.7246 - val_loss: 0.5519 - val_accuracy: 0.7360\n",
            "Epoch 295/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5605 - accuracy: 0.7246 - val_loss: 0.5514 - val_accuracy: 0.7360\n",
            "Epoch 296/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5604 - accuracy: 0.7246 - val_loss: 0.5512 - val_accuracy: 0.7360\n",
            "Epoch 297/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7319 - val_loss: 0.5508 - val_accuracy: 0.7360\n",
            "Epoch 298/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7246 - val_loss: 0.5504 - val_accuracy: 0.7360\n",
            "Epoch 299/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7246 - val_loss: 0.5500 - val_accuracy: 0.7360\n",
            "Epoch 300/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5585 - accuracy: 0.7246 - val_loss: 0.5498 - val_accuracy: 0.7360\n",
            "Epoch 301/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.7246 - val_loss: 0.5496 - val_accuracy: 0.7422\n",
            "Epoch 302/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.7246 - val_loss: 0.5493 - val_accuracy: 0.7484\n",
            "Epoch 303/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7246 - val_loss: 0.5490 - val_accuracy: 0.7484\n",
            "Epoch 304/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7246 - val_loss: 0.5487 - val_accuracy: 0.7453\n",
            "Epoch 305/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7246 - val_loss: 0.5482 - val_accuracy: 0.7484\n",
            "Epoch 306/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7246 - val_loss: 0.5479 - val_accuracy: 0.7484\n",
            "Epoch 307/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7246 - val_loss: 0.5473 - val_accuracy: 0.7453\n",
            "Epoch 308/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5560 - accuracy: 0.7246 - val_loss: 0.5470 - val_accuracy: 0.7484\n",
            "Epoch 309/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7246 - val_loss: 0.5466 - val_accuracy: 0.7391\n",
            "Epoch 310/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7246 - val_loss: 0.5462 - val_accuracy: 0.7453\n",
            "Epoch 311/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7246 - val_loss: 0.5459 - val_accuracy: 0.7453\n",
            "Epoch 312/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5546 - accuracy: 0.7319 - val_loss: 0.5457 - val_accuracy: 0.7484\n",
            "Epoch 313/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.7246 - val_loss: 0.5454 - val_accuracy: 0.7484\n",
            "Epoch 314/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7246 - val_loss: 0.5450 - val_accuracy: 0.7516\n",
            "Epoch 315/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.7246 - val_loss: 0.5448 - val_accuracy: 0.7516\n",
            "Epoch 316/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7174 - val_loss: 0.5443 - val_accuracy: 0.7516\n",
            "Epoch 317/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5530 - accuracy: 0.7246 - val_loss: 0.5438 - val_accuracy: 0.7516\n",
            "Epoch 318/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7246 - val_loss: 0.5434 - val_accuracy: 0.7516\n",
            "Epoch 319/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.7319 - val_loss: 0.5433 - val_accuracy: 0.7516\n",
            "Epoch 320/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.7246 - val_loss: 0.5430 - val_accuracy: 0.7547\n",
            "Epoch 321/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7174 - val_loss: 0.5425 - val_accuracy: 0.7547\n",
            "Epoch 322/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5511 - accuracy: 0.7174 - val_loss: 0.5422 - val_accuracy: 0.7547\n",
            "Epoch 323/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7174 - val_loss: 0.5419 - val_accuracy: 0.7516\n",
            "Epoch 324/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5508 - accuracy: 0.7246 - val_loss: 0.5417 - val_accuracy: 0.7516\n",
            "Epoch 325/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5506 - accuracy: 0.7174 - val_loss: 0.5415 - val_accuracy: 0.7516\n",
            "Epoch 326/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7101 - val_loss: 0.5411 - val_accuracy: 0.7516\n",
            "Epoch 327/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7174 - val_loss: 0.5407 - val_accuracy: 0.7516\n",
            "Epoch 328/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.7174 - val_loss: 0.5402 - val_accuracy: 0.7516\n",
            "Epoch 329/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7174 - val_loss: 0.5399 - val_accuracy: 0.7516\n",
            "Epoch 330/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7246 - val_loss: 0.5398 - val_accuracy: 0.7516\n",
            "Epoch 331/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7246 - val_loss: 0.5395 - val_accuracy: 0.7516\n",
            "Epoch 332/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5482 - accuracy: 0.7101 - val_loss: 0.5392 - val_accuracy: 0.7516\n",
            "Epoch 333/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5478 - accuracy: 0.7101 - val_loss: 0.5389 - val_accuracy: 0.7547\n",
            "Epoch 334/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7174 - val_loss: 0.5387 - val_accuracy: 0.7547\n",
            "Epoch 335/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7101 - val_loss: 0.5383 - val_accuracy: 0.7547\n",
            "Epoch 336/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7174 - val_loss: 0.5380 - val_accuracy: 0.7547\n",
            "Epoch 337/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5472 - accuracy: 0.7101 - val_loss: 0.5377 - val_accuracy: 0.7578\n",
            "Epoch 338/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7101 - val_loss: 0.5373 - val_accuracy: 0.7578\n",
            "Epoch 339/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.7174 - val_loss: 0.5368 - val_accuracy: 0.7547\n",
            "Epoch 340/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.7174 - val_loss: 0.5367 - val_accuracy: 0.7578\n",
            "Epoch 341/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7029 - val_loss: 0.5363 - val_accuracy: 0.7578\n",
            "Epoch 342/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5449 - accuracy: 0.7101 - val_loss: 0.5359 - val_accuracy: 0.7578\n",
            "Epoch 343/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7101 - val_loss: 0.5355 - val_accuracy: 0.7578\n",
            "Epoch 344/400\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.5451 - accuracy: 0.7101 - val_loss: 0.5353 - val_accuracy: 0.7578\n",
            "Epoch 345/400\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.5440 - accuracy: 0.7101 - val_loss: 0.5346 - val_accuracy: 0.7547\n",
            "Epoch 346/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7174 - val_loss: 0.5343 - val_accuracy: 0.7578\n",
            "Epoch 347/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5435 - accuracy: 0.7246 - val_loss: 0.5342 - val_accuracy: 0.7578\n",
            "Epoch 348/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5430 - accuracy: 0.7101 - val_loss: 0.5338 - val_accuracy: 0.7578\n",
            "Epoch 349/400\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5433 - accuracy: 0.7246 - val_loss: 0.5337 - val_accuracy: 0.7609\n",
            "Epoch 350/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7246 - val_loss: 0.5335 - val_accuracy: 0.7609\n",
            "Epoch 351/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7174 - val_loss: 0.5332 - val_accuracy: 0.7640\n",
            "Epoch 352/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5420 - accuracy: 0.7174 - val_loss: 0.5328 - val_accuracy: 0.7609\n",
            "Epoch 353/400\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5419 - accuracy: 0.7174 - val_loss: 0.5325 - val_accuracy: 0.7609\n",
            "Epoch 354/400\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5414 - accuracy: 0.7101 - val_loss: 0.5321 - val_accuracy: 0.7609\n",
            "Epoch 355/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7101 - val_loss: 0.5315 - val_accuracy: 0.7609\n",
            "Epoch 356/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7174 - val_loss: 0.5312 - val_accuracy: 0.7609\n",
            "Epoch 357/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7174 - val_loss: 0.5311 - val_accuracy: 0.7609\n",
            "Epoch 358/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.7174 - val_loss: 0.5307 - val_accuracy: 0.7609\n",
            "Epoch 359/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7101 - val_loss: 0.5303 - val_accuracy: 0.7609\n",
            "Epoch 360/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7174 - val_loss: 0.5302 - val_accuracy: 0.7609\n",
            "Epoch 361/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7246 - val_loss: 0.5300 - val_accuracy: 0.7640\n",
            "Epoch 362/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7174 - val_loss: 0.5296 - val_accuracy: 0.7609\n",
            "Epoch 363/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.7101 - val_loss: 0.5294 - val_accuracy: 0.7640\n",
            "Epoch 364/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7101 - val_loss: 0.5288 - val_accuracy: 0.7609\n",
            "Epoch 365/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7246 - val_loss: 0.5288 - val_accuracy: 0.7640\n",
            "Epoch 366/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7101 - val_loss: 0.5283 - val_accuracy: 0.7609\n",
            "Epoch 367/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7174 - val_loss: 0.5281 - val_accuracy: 0.7609\n",
            "Epoch 368/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7101 - val_loss: 0.5278 - val_accuracy: 0.7609\n",
            "Epoch 369/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7174 - val_loss: 0.5276 - val_accuracy: 0.7640\n",
            "Epoch 370/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7101 - val_loss: 0.5272 - val_accuracy: 0.7640\n",
            "Epoch 371/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7101 - val_loss: 0.5271 - val_accuracy: 0.7671\n",
            "Epoch 372/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7174 - val_loss: 0.5270 - val_accuracy: 0.7640\n",
            "Epoch 373/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7174 - val_loss: 0.5270 - val_accuracy: 0.7609\n",
            "Epoch 374/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7101 - val_loss: 0.5267 - val_accuracy: 0.7609\n",
            "Epoch 375/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7101 - val_loss: 0.5261 - val_accuracy: 0.7640\n",
            "Epoch 376/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7174 - val_loss: 0.5261 - val_accuracy: 0.7609\n",
            "Epoch 377/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7101 - val_loss: 0.5255 - val_accuracy: 0.7640\n",
            "Epoch 378/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7101 - val_loss: 0.5252 - val_accuracy: 0.7609\n",
            "Epoch 379/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5342 - accuracy: 0.7101 - val_loss: 0.5250 - val_accuracy: 0.7609\n",
            "Epoch 380/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7101 - val_loss: 0.5247 - val_accuracy: 0.7609\n",
            "Epoch 381/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7101 - val_loss: 0.5245 - val_accuracy: 0.7609\n",
            "Epoch 382/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7246 - val_loss: 0.5248 - val_accuracy: 0.7609\n",
            "Epoch 383/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7101 - val_loss: 0.5242 - val_accuracy: 0.7609\n",
            "Epoch 384/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7101 - val_loss: 0.5236 - val_accuracy: 0.7609\n",
            "Epoch 385/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7101 - val_loss: 0.5232 - val_accuracy: 0.7609\n",
            "Epoch 386/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5325 - accuracy: 0.7101 - val_loss: 0.5228 - val_accuracy: 0.7640\n",
            "Epoch 387/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7174 - val_loss: 0.5226 - val_accuracy: 0.7609\n",
            "Epoch 388/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7174 - val_loss: 0.5223 - val_accuracy: 0.7609\n",
            "Epoch 389/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7101 - val_loss: 0.5219 - val_accuracy: 0.7640\n",
            "Epoch 390/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7101 - val_loss: 0.5215 - val_accuracy: 0.7640\n",
            "Epoch 391/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7174 - val_loss: 0.5214 - val_accuracy: 0.7609\n",
            "Epoch 392/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7101 - val_loss: 0.5212 - val_accuracy: 0.7609\n",
            "Epoch 393/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7101 - val_loss: 0.5209 - val_accuracy: 0.7609\n",
            "Epoch 394/400\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7174 - val_loss: 0.5209 - val_accuracy: 0.7609\n",
            "Epoch 395/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7101 - val_loss: 0.5208 - val_accuracy: 0.7609\n",
            "Epoch 396/400\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.7101 - val_loss: 0.5204 - val_accuracy: 0.7609\n",
            "Epoch 397/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7101 - val_loss: 0.5203 - val_accuracy: 0.7609\n",
            "Epoch 398/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7101 - val_loss: 0.5200 - val_accuracy: 0.7609\n",
            "Epoch 399/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7101 - val_loss: 0.5196 - val_accuracy: 0.7609\n",
            "Epoch 400/400\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7101 - val_loss: 0.5194 - val_accuracy: 0.7609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "1a94724a-e259-49f4-f68c-f802ec4671cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXgUVfa/30PY931fEpDFhT2KijrgiooiigsyKjJuqLO4zajjKIM6Px2d0XFGHXfUUXEZZBBQv6KiIi4EDKKIECBA2GQLq5Dt/v44VenqTic0kHQnnfM+Tz9VdetW1anq5NO3zj33XHHOYRiGYSQvNRJtgGEYhlGxmNAbhmEkOSb0hmEYSY4JvWEYRpJjQm8YhpHkmNAbhmEkOSb01RAReVdErijvuolERLJF5NQKOK8TkcO89X+LyJ9iqXsQ1xkjIv93sHYaRlmIxdFXDURkV2CzPrAPKPS2r3XOvRJ/qyoPIpINXOWcm1XO53VAd+dcVnnVFZFUYCVQyzlXUB52GkZZ1Ey0AUZsOOca+utliZqI1DTxMCoL9vdYOTDXTRVHRIaISI6I/EFENgAviEgzEZkuIptEZJu33jFwzGwRucpbHysic0TkYa/uShE58yDrponIpyKyU0RmicjjIvKfUuyOxcZ7ReRz73z/JyItA/svE5FVIrJFRP5YxvMZJCIbRCQlUDZSRL711o8RkS9EJFdE1ovIv0SkdinnmiQi9wW2b/OOWSci4yLqni0i34jIDhFZIyITArs/9Za5IrJLRI7zn23g+ONFZJ6IbPeWx8f6bA7wOTcXkRe8e9gmIlMD+0aISKZ3D8tFZJhXHuYmE5EJ/vcsIqmeC+tXIrIa+Mgrf9P7HrZ7fyNHBo6vJyJ/877P7d7fWD0RmSEiv464n29FZGS0ezVKx4Q+OWgLNAe6ANeg3+sL3nZn4GfgX2UcPwj4EWgJ/BV4TkTkIOq+CnwNtAAmAJeVcc1YbLwUuBJoDdQGbgUQkSOAJ73zt/eu15EoOOe+AnYDJ0ec91VvvRC4ybuf44BTgOvLsBvPhmGePacB3YHI/oHdwOVAU+BsYLyInOftO8lbNnXONXTOfRFx7ubADOAx797+DswQkRYR91Di2URhf8/5ZdQVeKR3rkc8G44BXgJu8+7hJCC7tOcRhV8AhwNneNvvos+pNbAACLoaHwYGAsejf8e/B4qAF4Ff+pVEpC/QAX02xoHgnLNPFfug/3CneutDgDygbhn1+wHbAtuzUdcPwFggK7CvPuCAtgdSFxWRAqB+YP9/gP/EeE/RbLwrsH098J63fjcwObCvgfcMTi3l3PcBz3vrjVAR7lJK3d8Bbwe2HXCYtz4JuM9bfx54IFCvR7BulPM+Cjzirad6dWsG9o8F5njrlwFfRxz/BTB2f8/mQJ4z0A4V1GZR6j3l21vW35+3PcH/ngP31rUMG5p6dZqgP0Q/A32j1KsLbEP7PUB/EJ6I9/9bMnysRZ8cbHLO7fU3RKS+iDzlvQrvQF0FTYPuiwg2+CvOuT3easMDrNse2BooA1hTmsEx2rghsL4nYFP74Lmdc7uBLaVdC229ny8idYDzgQXOuVWeHT08d8YGz46/oK37/RFmA7Aq4v4GicjHnstkO3BdjOf1z70qomwV2pr1Ke3ZhLGf59wJ/c62RTm0E7A8RnujUfxsRCRFRB7w3D87CL0ZtPQ+daNdy/ubfh34pYjUAEajbyDGAWJCnxxEhk7dAvQEBjnnGhNyFZTmjikP1gPNRaR+oKxTGfUPxcb1wXN712xRWmXn3GJUKM8k3G0D6gJagrYaGwN3HowN6BtNkFeBaUAn51wT4N+B8+4v1G0d6moJ0hlYG4NdkZT1nNeg31nTKMetAbqVcs7d6NucT9sodYL3eCkwAnVvNUFb/b4Nm4G9ZVzrRWAM6lLb4yLcXEZsmNAnJ43Q1+Fcz997T0Vf0GshZwATRKS2iBwHnFNBNr4FDBeRE7yO04ns/2/5VeC3qNC9GWHHDmCXiPQCxsdowxvAWBE5wvuhibS/Edpa3uv5uy8N7NuEuky6lnLumUAPEblURGqKyMXAEcD0GG2LtCPqc3bOrUd95094nba1RMT/IXgOuFJEThGRGiLSwXs+AJnAJV79dGBUDDbsQ9+66qNvTb4NRagb7O8i0t5r/R/nvX3hCXsR8DesNX/QmNAnJ48C9dDW0pfAe3G67hi0Q3ML6hd/Hf0Hj8ZB2+ic+x64ARXv9agfN2c/h72GdhB+5JzbHCi/FRXhncAzns2x2PCudw8fAVneMsj1wEQR2Yn2KbwROHYPcD/wuWi0z7ER594CDEdb41vQzsnhEXbHyv6e82VAPvpW8xPaR4Fz7mu0s/cRYDvwCaG3jD+hLfBtwJ8Jf0OKxkvoG9VaYLFnR5BbgUXAPGAr8CDh2vQS0Bvt8zEOAhswZVQYIvI6sMQ5V+FvFEbyIiKXA9c4505ItC1VFWvRG+WGiBwtIt28V/1hqF926v6OM4zS8Nxi1wNPJ9qWqowJvVGetEVD/3ahMeDjnXPfJNQio8oiImeg/Rkb2b97yCgDc90YhmEkOdaiNwzDSHIqXVKzli1butTU1ESbYRiGUaWYP3/+Zudcq2j7Kp3Qp6amkpGRkWgzDMMwqhQiEjmauhhz3RiGYSQ5JvSGYRhJjgm9YRhGklPpfPTRyM/PJycnh7179+6/spEQ6tatS8eOHalVq1aiTTEMI4IqIfQ5OTk0atSI1NRUSp8Pw0gUzjm2bNlCTk4OaWlpiTbHMIwIqoTrZu/evbRo0cJEvpIiIrRo0cLeuAyjklIlhB4wka/k2PdjGJWXKiP0hmEYlYIPP4SFCxNtxQFhQh8DW7ZsoV+/fvTr14+2bdvSoUOH4u28vLwyj83IyOA3v/nNfq9x/PHHl5e5hmFUFPn5MGoUXL/f+eMrFVWiMzbRtGjRgszMTAAmTJhAw4YNufXWW4v3FxQUULNm9EeZnp5Oenr6fq8xd+7c8jHWMIyKY+5cyM2FL7+EzZuhZazTACcWa9EfJGPHjuW6665j0KBB/P73v+frr7/muOOOo3///hx//PH8+OOPAMyePZvhw4cD+iMxbtw4hgwZQteuXXnssceKz9ewYcPi+kOGDGHUqFH06tWLMWPG4GcYnTlzJr169WLgwIH85je/KT5vkOzsbE488UQGDBjAgAEDwn5AHnzwQXr37k3fvn25/fbbAcjKyuLUU0+lb9++DBgwgOXLD2U+aMOoAuzYAUcfDbNnR98/bRqccAIMGwZjx8Ixx8CuXTBnDgwZonWKiuC99+CGG+CXv4Q+fWDlypLn+uQTSE+HNWugVy847DDYtKmCbqx0qlyL/ne/A69xXW706wePPnrgx+Xk5DB37lxSUlLYsWMHn332GTVr1mTWrFnceeed/Pe//y1xzJIlS/j444/ZuXMnPXv2ZPz48SViz7/55hu+//572rdvz+DBg/n8889JT0/n2muv5dNPPyUtLY3Ro0dHtal169Z88MEH1K1bl2XLljF69GgyMjJ49913+d///sdXX31F/fr12bp1KwBjxozh9ttvZ+TIkezdu5eioqIDfxCGUZV4/33IyIDnnw8Jd5Cnn4bPPw8vmzULZs7U9Weegbvugtdegw8+UHcOwOuvg9eAKua552D+fBUur/HHO+/AuHHlekv7o8oJfWXiwgsvJCUlBYDt27dzxRVXsGzZMkSEfP/Lj+Dss8+mTp061KlTh9atW7Nx40Y6duwYVueYY44pLuvXrx/Z2dk0bNiQrl27Fsepjx49mqefLjnpTn5+PjfeeCOZmZmkpKSwdOlSAGbNmsWVV15J/fr1AWjevDk7d+5k7dq1jBw5EtBBT4aR1KxfD3feqeszZ8KrEfOZOKedrZE89ZS2MEeNgquuUhfOCy+E13ntNejcObzM/3GYMgVatIC6dfW40v7XWrSAM8448PvaD1VO6A+m5V1RNGjQoHj9T3/6E0OHDuXtt98mOzubIdFaCkCdOnWK11NSUigoKDioOqXxyCOP0KZNGxYuXEhRUZGJt2EEueEGyMpSF0pWFowZE71ejx4q+itXQrdu6qYBuOACXY4apYLdvLm6cdq0gW+/jX4+/1rnnw8NGqiIzZkT/bqDBpnQV2a2b99Ohw4dAJg0aVK5n79nz56sWLGC7OxsUlNTef3110u1o2PHjtSoUYMXX3yRwsJCAE477TQmTpzImDFjil03zZs3p2PHjkydOpXzzjuPffv2UVhYWNzqN4ykYu9e+L//g+HDtYW9bh3s21eyXr160Lq1Cnhenm5nZ0Pt2tCli9Y56yxYtQoaNYKUFKhfX+tEuj7r1IH27XVfaiqIaMROaTP7VVDDzIS+nPj973/PFVdcwX333cfZZ59d7uevV68eTzzxBMOGDaNBgwYcffTRUetdf/31XHDBBbz00kvFdQGGDRtGZmYm6enp1K5dm7POOou//OUvvPzyy1x77bXcfffd1KpVizfffJOuXbuWu/2GUeE89JB2pJ52mvrOfdHt0EFb3HPmwO7dMH481KoVEu2yqFdPlz16lNwX6aY57LDSz9O9e/T1OFHp5oxNT093kROP/PDDDxx++OEJsqjysGvXLho2bIhzjhtuuIHu3btz0003JdqsYux7MhJGXp6GOu7cqduNGqkbZPt2mDdPy448Evr21U7YgHs0WRCR+c65qLHc1qKvQjzzzDO8+OKL5OXl0b9/f6699tpEm2QYFcOOHbB8ubaoe/ZUl0c0tm5VF0pmpop827awYQNcein8+99a1rKl/hBMngxHHRXf+6gkmNBXIW666aZK1YI3jArj/PND0S/vvw+nnx693pAhsGiRrtevD//8J1x4IYwYoWWNGsGpp8KSJdqir6bENGBKRIaJyI8ikiUit0fZ/4iIZHqfpSKSG9hXGNg3rTyNNwwjCdm6FT7+GC67DBo2hLffjl4vK0tF/sYbYepU+OILjYrJyNDBTj6TJun5qnHivf226EUkBXgcOA3IAeaJyDTn3GK/jnPupkD9XwP9A6f42TnXr/xMNgwjqfjpJ5gwIRQBs26ddqTecIOOSH3zTXW9RLJihS5vugmCAQQDB4bXa9WqQsyuSsTiujkGyHLOrQAQkcnACGBxKfVHA/eUj3mGYSQ9kybBk09CcODgySdrmoKrr4YFCzQsMhoXXBAu8kZUYhH6DsCawHYOMChaRRHpAqQBHwWK64pIBlAAPOCcmxrluGuAawA6R4YsGYZRtdm3T2PQCwrUfRJMAFhUpDHt/furoEdy5pkag24cEuWd1OwS4C3nXGGgrIsX8nMp8KiIdIs8yDn3tHMu3TmX3qoSvmYNHTqU999/P6zs0UcfZfz48aUeM2TIEPww0bPOOovc3NwSdSZMmMDDDz9c5rWnTp3K4sWhl6e7776bWbNmHYj5hpE4Xn5ZBwENGgRNmmg8e8OGoTQEQ4fCV19BBYw9MULEIvRrgU6B7Y5eWTQuAV4LFjjn1nrLFcBswv33VYLRo0czefLksLLJkyeXmlgskpkzZ9K0adODunak0E+cOJFTTz31oM5lGHHHH+o/bx78/LN2tO7eDf/v/8Hq1fDppzBggCb9MiqMWIR+HtBdRNJEpDYq5iWiZ0SkF9AM+CJQ1kxE6njrLYHBlO7br7SMGjWKGTNmFE8ykp2dzbp16zjxxBMZP3486enpHHnkkdxzT/SuidTUVDZv3gzA/fffT48ePTjhhBOKUxmDxsgfffTR9O3blwsuuIA9e/Ywd+5cpk2bxm233Ua/fv1Yvnw5Y8eO5a233gLgww8/pH///vTu3Ztx48axz+vMSk1N5Z577mHAgAH07t2bJUuWlLDJ0hkbcWHpUqjhycyRR4bytzdurOl9AV55RZN5GRXGfn30zrkCEbkReB9IAZ53zn0vIhOBDOecL/qXAJNd+FDbw4GnRKQI/VF5IBitc1AkIE9x8+bNOeaYY3j33XcZMWIEkydP5qKLLkJEuP/++2nevDmFhYWccsopfPvtt/Tp0yfqeebPn8/kyZPJzMykoKCAAQMGMNCLEDj//PO5+uqrAbjrrrt47rnn+PWvf825557L8OHDGTVqVNi59u7dy9ixY/nwww/p0aMHl19+OU8++SS/81pGLVu2ZMGCBTzxxBM8/PDDPPvss2HHWzpjIy4sXaqJvhYsgCuvhJwc/V/bsQM++0xztPfsmWgrk56YBkw552YCMyPK7o7YnhDluLlA70Owr9Lgu298oX/uuecAeOONN3j66acpKChg/fr1LF68uFSh/+yzzxg5cmRx0rBzzz23eN93333HXXfdRW5uLrt27eKM/WSw+/HHH0lLS6OHl4Pjiiuu4PHHHy8W+vPPPx+AgQMHMmXKlBLHWzpjo8LZtUtDJQ8/HF56KVRepw48+KAmA1u0qFrHt8eLqjcyNkF5ikeMGMFNN93EggUL2LNnDwMHDmTlypU8/PDDzJs3j2bNmjF27Fj27t17UOcfO3YsU6dOpW/fvkyaNInZpc1+EyN+quPS0hxbOmOjwlm2TJeRCcHat9dlu3bhEThGhWFTCcZIw4YNGTp0KOPGjSvuhN2xYwcNGjSgSZMmbNy4kXfffbfMc5x00klMnTqVn3/+mZ07d/LOO+8U79u5cyft2rUjPz+fV155pbi8UaNG7PQTNQXo2bMn2dnZZGVlAfDyyy/zi1/8Iub72b59O+3ataNGjRq8/PLLYemMX3jhBfbs2QPA1q1badSoUXE6Y4B9+/YV7zeMUvHeEksIfbt2umzUKL72VGNM6A+A0aNHs3DhwmKh79u3L/3796dXr15ceumlDB48uMzjBwwYwMUXX0zfvn0588wzw1IN33vvvQwaNIjBgwfTq1ev4vJLLrmEhx56iP79+4d1gNatW5cXXniBCy+8kN69e1OjRg2uu+66mO/l+uuv58UXX6Rv374sWbIkLJ3xueeeS3p6Ov369SsO/3z55Zd57LHH6NOnD8cffzwbNmyI+VpGNcUX+sj0vX6HrDdPslHxWJpio9yw78kI47LLdHLs1avDy1eu1NGsf/+7pi8wygVLU2wYRvxZujT6hB1paZpKuHXr+NtUTTGhNwzj4Jg5E777Dr7/XoU7koULYdy46Me2aVOxthlhVBmhd84hFoZVaalsLkAjDvzrX+AHIPTqBZGjv9PT4eKL42+XUYIqIfR169Zly5YttGjRwsS+EuKcY8uWLRaiWd3wwydBZ2/q2zdxthhlUiWEvmPHjuTk5LBp06ZEm2KUQt26dekYTDNrJDd5ebiVKyludnmRNc7B4sWxT+a0dq1ODNWsWajs559h/XrLPlyeVAmhr1WrFmlpaYk2wzAMn5UrEW/sBR07ghee+9FHOnPfN99oZpH9ceaZmtNs0qRQ2d//Dg88oPnPatUqf9OrIxZHbxjGgePHyANFh3UvXvcTrf7ww/5PUVioU7kujsh+tXixZk/IySkPQw0woTcM42D48ksKSGEKI9l64nnFxStXhi/LYt06yM8vWfdAzmHEhgm9YRgHTNE705nDCVzAFBb+4jfF5f5kULFMCuXX2bxZW/AHcw4jNkzoDcOInVtugZQUaiz6lhnorFDBlveBtMaDdXxR9ztiYz2HERtVojPWMCobpQ36LG/27NEWb+RUykuX6sDSvXuhbdtQuXMa9Rhp2+rV0KoV1KsX23XXr9exUEHq1S7k+BcmsbN7Ot+mnsOz718FaJaDLl20zooVulyyBD74oOxrBBO0TpumMw5++22ozBf/bdsgLy98jFVmpk43O2BAbPcD+lxatYKMDA3xL23St3371K2UlqbT3K5efWARQHl5Gk1UqeJHnHOV6jNw4EBnGJWZzEznwLm5cyv+WmefrdcqLAyVzZ2rZeDcgAHh9R95RMsXLAiVFRY617Spcw88UMaFVq927sknnVu61Ll169xfuz7pruOJsM9E7nIO3EVMduBcjRrOtW0bssX/dOxYsqy0T5s2ztWsqetNmoTKmzd3bvBgNe2ii5w77riQqTk5oXqrVsX2HFeuVHs7ddLjxo4tve6jjzpXr55zu3Y59+KLztWu7dy2bbFdxznn/v3v0PHxBJ0IKqquWoveMA4QP0fXmjVw3HEVe60ZM3S5YUMojfuaNaH9ixer5PnjCP3669dDf2925l27IDc3/LgS3HMPvPCCTtbduTO3rXgxarXtNGbncWcw5yFNQtm4cagVD5pe/qijtGUeyyRkaWlq35NPhqaauOMObVHPmqXb332nETj+fQYCftiwoeTbTjR++EHt8Z9BlNk1i/nuO3UhZWfrd52XBz/9VPobQCSrV+vxW7YUR50mHBN6wzhAcnPDlxVJw4YqhNnZIaGvEehZ27sXNm4MuW98m/wQ92BZmfb68ZCzZ+Nq1uRNLmTDnf/kN14/q3Pqvvjp54b8Kr0BwYzcfnr5IAf6A/iLX4SEfsQIeO89Fft9+/Te9+xR+5s1C++kjfU7iOzYLaujN9gZfDDfdfCYWH6E4oF1xhrGARJPofdHjAY7JrdvD68T3BfNtm3bIsp++Usduup/+vWDL7+E3r3BOSQ/n7cZSZs+bdQx3qYN0rYN9dPasIcGFeJ7Dp4zNVU/zsH8+SrywfsM3q9/b/sjsmN3wwZtdZdVd+XKKM8uBuL59xErJvSGcYD4//yxisyh0LixLoMt0MjrRmvhBuuElS1bBq+8oic+4gj9LFyoFS6/HH77W1afOo5pnEtqavh1/O3I8vLAP2e9etrJ7G9//HGoTrCl7c9AeDAten+07apVJesVFoZcc8EW/YF81wdzTEVjrhvDiIHVq9VFUatWyRbb8uXq1ojMt1dUBF9/rcKVlgbz5sHu3eF1RNSXvmiRDh4aMECjbLp1UyHy48u//DIkej/+GH6O2bPVL960qR7r27ZkCWxctZcln22iOz+Tlr2WHQ++Q2Ng1f97lab90/jmGzjpkzbU2PQT3+b1YsuIW/kfsGdWyagRf7siWvRNmujbS9u2+kz8a0yfHqqzbBnMmaPPql8/jZ7JzdXn1Lw57Nih7q2MDD1fMPIo2KLv10+/i3fe0XnKU1P1e9qzR59hfr7WCwr9kiWwcyds2qTf9eLF6lbq31//Ntq2hdq1tW7k38eOHbBggX63KSm63bat9m1061beT7IUSuulTdTHom6Mysbu3eGRGldeqduXXOLcjz86J+LczJklj3vvPa1Xu7Zzn3xSeuRJu3ah9U6dNDokM9O5unXLjlipW9e5Vq10XcS5Zs1C+66+Wq/7PGOdA7eL+sU793Tv40RCESgPNpzoHLhuLAuLeikqCr8fP5pk+/aKec4nneTchRfqekGBc40ahZ5f/frh93fNNc7VquXcddc5V6eOc6mpzrVo4dycOaE6+fmhc7dsGSq//np9xqBRQ7Nmhfb516hXTyOaBgwI7UtNdS4lJRR1Bc5lZDjXoIFGO/kcfrjue/RR3R43LvSd3HKLc507O/fhh1q2aFH5PT/KiLox141h7Ad/bnY/8VawxeZHvXz/fcnj1q7VZV6etkIB3npLW+D+p1cvjZCpVUtbfGvW6JvAjBna0Qpw1VWh+iNGaFmXLtqyz8iAf/xDbdi2DU45RVuL33yj1x1ZUyegb8AeruNJfsFsnjr/fZwLRaD8YdddHEYWT394WPF1MjJKvqH86lfasvXdSeXNlCnwzDO6npKi9zB7tkbw9Oih91e7tpY9/LC2vjMyQh22W7aEx+b739OuXaE3HdBzLVoEN96ovvovv9TyY48NuVsGD9ZzBt0v2dnq2vEjmwDef1/f0oLff2SL3o/w+eEHjehZvRq++ELLIvP8VBTmujGM/RDpbgn6YMsaCRr0H2dmql/5vPNUxHyOOEKFoEsX7QtdsABO5FOaT8oAbgage3eNSgGYOxf+9z8dXORHdJzXfxV5/JM/cS//KLiV9Xs2sGM+vMYlFDRrDZu2sI2mPMevKKAWtcKnZAaEvR26cfLJZT+HmjUrNoqkRYvw7W7dQq6N1FR9hqmpoWfRrJn+GAQJ+vRzczUE1PfP16mjPwrNmulzHzJE5075+GN9nqecEhL9k07S8M7Iju/Ia/jr0TrE/R8Jf192tqZkhtAPUrxG/5rQG8Z+iBT6YCRGWXlZIoW+c+dwkYfwDk5/fQITGLJsNn/iMjbTKix+268TFKAOUx/nVv5GPrU48pMnaFK3G/XdVvqwkGY71gHwALdTgPZCBoWqRg19g6iIDtbyJFpHcNOm4WGkUFLoIfTd9O6tbwD+8wx2+HbvHuoXaN8eevbU9cjzB69Ro0Zo3b/Gvn2haJ7cXH0rW79e6+bkhN6SIo+raMx1Yxj7wQ/vA3WRBF/NY23RL1oUvRMzLQ0asYN+bdZzRLP1dCOLE/mMGjgu4g3asp62br2qxfr19Gi0nrasp87WUFnKu9pjeQcPUFSrNrcM/Ya7uI/DWE7Kvp+5hqf4K38ovmZwINOQISE7KjPROoKjDWAqKioZkeN/N35+fP84/1xFRboevEZZz6OwUN8Ujjoq9EOwerWuB3+A/Y5i0HFooH8//jmCtlU01qI3jAh279ZWWcuWugz+My5eHJ6Dxfe/ZmfDZ5+Fn8cP0wNt6UVrNfdqmMMmulHnlTx4BS7y61Obx7mRx7kRrkM/wEBgPUAe0D50njypTW2XB78YQp2WjbyEYzcAsIRepd7r0KE6WUhVbdFHw4/IycxUd80XX6jLxI/C8Y9r1gwaNdI+mOAbVXC9LHvatw/l5snP13w9fr8KqMjPnKnrQ4fChx+WPM+PP4b/3TRqFNuELQeKCb1hRDBokHauOQenn64hfT6+f7h9ex25uWyZdn5u2KB+3Uhq1tTEWBC9lXhkfiZ1yGPpqDtpc3Rn7rgDCps2J2NrV9JRZ/pttxbP1IdzcN14OPIIiketUrs2D3xwHPkffsq9T51K+6dhNV24//gZ/PGGXOaMOaHEdTt00GH9w4fDhAmxT/2XKI44Qt0eQTv9kcIdOmjHt/+dHHusCv1tt4Xq9u+v/SA1a4ZGEYuoiyYjQzvFO3VSoT3ySP2RT0kJd92kpOixa9dq/Q4dVNz97//888Nty8zUT40acPbZcNdduq9lS+0cbttWG9l9pD0AACAASURBVAjBv5tBg0L9BOWJOP9dopKQnp7uMjJK9BYZRtzw/ajBHDJB2rfXln1mpgrBgAHasvPjrwHuvFNjs7t3h3bLPmEP9fndf45mzJiIk/3973DLLbhNm5GWLcjK0gyL8+dry27LFj1HkJwcjRv3O/ZAW6W7dmms/+7d8NVXOld3ixZ6DtCp+Zo31/FRAweG4vWzsjQ2vEYld+QuXarPwv9Odu3SZ9y/v8a3N26sb1hHHaXPEOC3v4VzzlFh9oU1GLvu/1gfe6y2/let0sHAdevq+IiNG/VHZt8+jX9v3Vq/m/79NQLo66/V95+VFerL8d8eMjN1u1Ur6NNH/0YKC/UcWVn6/S5YEO5Ka9wYjj764J6PiMx3zqVH3WdCbxjh+EJSUBDy9wa58kp4/vmyz3HttfD003D6qUW8P0t7YOd+7jj++IiK48fDG2+E1Ng4ZJwL/WhNn66t6epAWUJfyX/DDSNxlDa8PpYshr6bph+h+L+oft94JbavRgTfwip7J3O8MKE3jFLIyopeXqbQf/YZtGrFzRObkEsTJn4U8o+3rb8jvO5dd2lPaKRvxig3/AlRqjsm9IZRCpGDcfxcJmUK/csvw969bBo+jucZx5RW1zG7/lkA1Fi+LFSvsBCeekrzEN96a/kabhRTWfLBJ5qYom5EZBjwDyAFeNY590DE/kcAL1KU+kBr51xTb98VgNffzH3OuegzGhhGJSM4rR1oON7GjaHUwWHk5Ohwx3fegTPPhEce4eY34eYxsG3O9wz5eia89FIo7/vatdob+tpr2lNnlCv+QDBD2a/Qi0gK8DhwGpADzBORac654iwNzrmbAvV/DfT31psD9wDpgAPme8dWogSehhGd5cvDt32hj9qiv/lmePNNXb/gAjp00GiOLl1g67puFPVpQo3HHgs/pkEDOOOMCrG9uvPTT9FHtVZXYmnRHwNkOedWAIjIZGAEUFo6ntGouAOcAXzgnNvqHfsBMAx47VCMNox4EDk83Rf4qEK/eDGcdho8+6wGZBOKfW/TpS5krywZWdOsWSmvB8ahEpk3p7oTi9B3AIKzTeYAg6JVFJEuQBrwURnHdohy3DXANQCdK8vcW0a1JPi6n50d7gIoVegLC7Xn9qyzSs/6ZaJuJJDy7oy9BHjLOXdAL03Ouaedc+nOufRW/kgHw0gAwbw2eXnhLcNShX7NGh1RY2GSRiUllhb9WqBTYLujVxaNS/ATbISOHRJx7OzYzTOM+LFxo+YLD9K0KRRs2kpXVtA3Hz6jLc33ABkbQpX8AX4m9EYlJRahnwd0F5E0VLgvAS6NrCQivYBmwBeB4veBv4iI/856OnDHIVlsGBVE374q9kGaNoVJDOd4voD/wngaUz+9KDTHn0+NGjrO3jAqIfsVeudcgYjciIp2CvC8c+57EZmITl01zat6CTDZBXIqOOe2isi96I8FwES/Y9YwKhO7d5cUeYBmTYo4tt5C9p18PnLcsTS56/ewC/jb38Jb8G3bahITw6iEWK4bw0CDZp488p8MZD4A9erC03svo8fwnjw5vRM88QSMG6dO+5QUjYGvVSvBVhtGiLJy3ViaYsMAcr7dyqP8jlyaspNGtMnbRBeWMHvfX7RCjx6a3vDmm1XoTeSNKoQJvZE8FBbqTCG1a4fyFcTCvn2kzJhGCkWcxUy+ZhDTj76XM7+6h1WrP9E6vptm4sTyt9swKhjLdWMkD/3768wRrVura6UMiscuLV0KTZpwyn+uZCOt+amzJgPfNng4NXBc/ONETTDeocTwD8OoMpjQG8lBbq5OzHrCCTpx57vvllp10SKdDGLRImDKFNi3j1ePvJ9bOr/FiJH6L9H+rH78kpeZ/ouH4L//rfyzchhGGZjrxkgOlnmZIW+6SUepTp8Ol10Wterq1To5xZo10Hv6dBgwgL9xJ607waSHtc+1Tx+h9aJfqsfmALxAhlEZsWaKkRwsXarLXr10SqH33guf2y+AP+Vb/oYtOnP08OFkZ+skFTVrhpJJHnXUgbn6DaOyYkJvJAfLlunUQt26qdDv2AGffx61qi/0zb56D4qK2DXkbLZuLWUGKMNIAsx1Y1QeNm6EESPguefgyCPD9y1cCOefrzllfLp3h0mTYNgw9cd06aIhkKeeqk3x887TiT0iuHC35txu/eJ2aN2aFc009NimnTOSFRN6o/IwZQp89ZVO0PHgg+H7/vMfdapffrlur1unHa5/+AMsWQJXXKETfoBG3vzrX3quKCxfCPMy4Jg+0Oe2M1i5Sl9srUVvJCsm9EblYO1auO8+XZ8yBY47DgYN0vn88vLg7bdhyBDN9w6wdauGzrz+urb+J00KP9/VV+snClPugYkZcM9Z0OdCWP1PLbf5RY1kxYTeqBxceqm20jt31qiZkSOhcWP1tfsE51Zt3hyGDoUPP1SXzgHg++j9pX+JJk0OwX7DqMSY0BuJZ8sWmDMHLr5YW+ZZWfDnP8Nbb6kf/o03NBzmiCPCj3v7bVi5Eg4//IAuFyn0e/ZoVgOLsDGSFYu6MRLDp5/CbbfpCNaBA3Uap5tvhrp1Na5x9Gitd8450K+flkUOWmrUSGMhDzDvTKTQ796t07eKHOI9GUYlxVr0RmL4619hxgz1v69apR2p6YHEe8OGqTvnmmvK/dKlCb1hJCsm9EZ82bVL3S0ffqjbjz2ms2jPmBHepK5fH1555ZAvV1CgvyX16+tLQ1aW9uOCumx271YfvQm9kcyY68aILyefrO6WvXtD6nrOORXmN5kwIfSi8OCD0LMnzJ6t27t3a5j9G2+Y0BvJjbXojfixejXMmwdXXaWDmXr2hAUL4IwzKuySCxbADz9o9uLs7PB9we369SvMBMNIOCb0RvyYMUOXt96qIg/qtqlAVq7UZXa2JrgMsnp1aN1a9EYyY64bI35Mn67CHpxrtQJxLtRqz86GbdtKr2tCbyQzJvRGfNizBz76SBOOxSmOceNG7QqA6C36ICb0RjJjQm+UL1OmaIt9167w8o8+UtUdPjxupgR98LNna4veT0EciQm9kcyY0Bvly6RJmjJ41qzw8unTNcTlpJPiZsqqVbqsXVsja7KydOxVNKwz1khmrDPWKD9+/jkk8P/8J+TkhPb9739w+ulxzTPgx8vPnKmZi0Gnfl2wQPOhffYZvPmmZlKwFr2RzJjQG+XHxx+r2Pfooa6ajz4K33/xxXE1x+98HTxYM1OuWgVNm+oc4qBZFpYtU6G39AdGMmNCb5Qf06dr0zgzM5RfwKdmTVXZOJKbq6lz6tbVS/tCH8R/wcjLi6tphhFXTOiN8mPGDDjtNKhXTz8JJjc3JOzNmukyUuj9fGilTC9rGEmBdcYa5cO2bToCafDguF0yP18v6VyozLnQbIO5uaULvI/fojehN5IZE3ojFOM+a1bos3Zt6fWzsjRbWJBly3Tpj3iNA2PGqO/90UdDZVOnakfrjh362+ML/HHH6bJ58/BzdOumywoeoGsYCcVcN4ZO8vHXv4aXHXUULFpUsm5Ojk708eCDmj/e58cfddm9e8XZGUFWli6XLw+VzZsHO3fC+vXaom/VSstvvRWOPlonpQpy1lnahxzHqE/DiDvWojc09PHEEzXe8LPPdEKQ774LV1CfGTO0Nf/22+HlS5fqxCBdu8bHZkIjXYMjXv3cNrm54T76GjVKirzPkCEl5zQxjGTCWvTVnawsbY3fcAOccIKWtWsHDz0El1yigedBMjN1OXcujBgRikv85htIS4trnHw0ofdHw/pC7/voDaM6Y0Jf3Zk3T5dDhoTKunWDsWNVvCNz+zZtChdeqC1/f+gpqKJedFEFGxuiqAi2b9f1aEK/bVu4j94wqjMxCb2IDAP+AaQAzzrnHohS5yJgAuCAhc65S73yQsB39q52zp1bDnbHhnMaTmGzPpekqEhdMEuXaqs80rf+wguJsQs1zTn91KypUTS+v905nch72zatB7peUKBf9YYNWpaVBYWFJvSGATH46EUkBXgcOBM4AhgtIkdE1OkO3AEMds4dCfwusPtn51w/7xM/kQe4916oUyeUwtAI8ec/Q69eOitHly46qqiScMYZKvC1asGrr6pvvW1baNxYyxcuhJYtta4ILF6s3ia/PxjgT3/Spd8ZaxjVmVi6oI4BspxzK5xzecBkYEREnauBx51z2wCccz+Vr5kHyT/+oUt/7jgjxGuvac/l66/HLT98rATzob31Vihy0x9s+/XXof2pqbrcvFmjZ4L07KleJsOo7sTiuukArAls5wCDIur0ABCRz1H3zgTn3HvevroikgEUAA8456ZGXkBErgGuAejcufMB3UCp/Oc/ofUZM2DYsPI5b1UhPx8efjjkyA7y888h9YRKJ/RBmjYtmfE4GPWZmhqKtIkU+ltusWRlhgHl1xlbE+gODAE6Ap+KSG/nXC7QxTm3VkS6Ah+JyCLnXFjcnnPuaeBpgPT0dMehsmkTXHZZaHvOnEM+ZZVj5ky4807tn4iWsatNG+jdW6NnTj45/vbFSK1aJT1v33wTWk9LCwn87Nl6u37emrS0uJhoGJWeWIR+LdApsN3RKwuSA3zlnMsHVorIUlT45znn1gI451aIyGygPxAlQLscWbo0fHvZMu3Fq04pCqdPV6f25s2hhC5VkGgDdP0ITwi5bkAHSnXvHnpZCe4zjOpMLD76eUB3EUkTkdrAJcC0iDpT0dY8ItISdeWsEJFmIlInUD4YWFxOtpdOUOgHD1bn7vr1FX7ZSsPNN8Ozz2qvZhUSeT/aJojvlundO1QWdOU0ahReP9iKLy8voGFUdfYr9M65AuBG4H3gB+AN59z3IjJRRPwomveBLSKyGPgYuM05twU4HMgQkYVe+QPOufgJ/UMPqfsiWJbs5OfDc8+pc3vChERbc0Acfjjcf394mR8Xf/TR0Y/p0iV8u1u30G+bRdUahhKTj945NxOYGVF2d2DdATd7n2CduUBv4s3SpRpyceutoUE9GRmap6WwMO7mlDu1asF552mweNBhDaqMO3Zodq8jjoh6eGUkN1e/tvff1+2rroL580O3d+WVkJ4O11+v2488ouJ//PHa1961q/rozzkH7rgjNLuUYRjJOjJ2+fJQWsJOnXSu0rvuCuWvTQYefBD+9S9Ys6bkviZN4JRT4m/TIeC33H3/+ymnaHCQL/QtW+qMUL7QDxwYyoh81lm67NUrdL5OwV4lw6jmJKfQr1sHxxyj6zVq6IShU6eqMrz8cmJtKw/OO099HDt2wN/+BiNHhu9v1kx/3KoQvi/e9783bRo+qrVpU+1bFlE/vnW0GkbsJJ/Q5+dreGX79qGy4cNV6EeOTI6Yu3PPhfvu0/UxYzRUsooTLaVOpNDXqKFiv2dP+NdrGEbZJJ/Qb9yoy3btQmWjRulwymBsfVVm3Dj4/nsNRUkCkYfwkEnQl5Jg5kk/Q0OzZurGSUmJn22GUdVJPqH3wyiDQt+kCTz1VGLsqQjS0mDKlERbUW688AK89JKKuT84qnnzUD6boBeqVauSs0QZhlE2ySv09m5fZfAzJX/2meZYa9BABf2CC7T/PNjJ+vzzmqfOMIzYST6hX7dOl8EWvVGpWbkSBgzQ8Mn09FB5w4ZwzTXhdY86Kr62GUYykHwTqK1fr6EZSeK7rg5kZydHH7lhVFaST+hXrdLWfM3ke1lJRpxTobdwScOoOJJP6P1RsUaVICdHO2CtRW8YFUdyCn3ktHhGpWLOHPWuZWaGBjB37ZpYmwwjmUkuod+6FbZsqdQTaRjwzju6fOopHd923HE6eNkwjIohuYTeT0RuQl+p8Ue8+nls7rmnSmVTNowqR3IJvT+O3hy+VQJf6O3rMoyKJbmEfvNmXbZqlVg7jDLxp7H1p/yzCUIMo2JJrhjELVt0aWPk445zmmysZk0duVpYqP73unV1gq8g27aF1tu3D+WxMQyjYkiuFv2WLZre0By+caGgQAOcXn1VJwpp2FA/8+frSNd69WDIkFC5/3n66dA5LNrGMCqe5GvRt2iRaCuqDWvW6CRXc+bA3Lmhibk//xy+/VbrfPKJ+uDHj9ftSZNg8WLo0AFuugmGDk2Y+YZRbTChNw4av+97xQpdHz9eJ7365JPweoMGwW236fry5Sr0Rx0Ft9wST2sNo/qSfK4b88/HDV/ov/pKR7d266aTdX/8cXi9YFSNv24ZKgwjfiSX0G/dai36OOJP/5ebq8vUVP34na1HHx0q9/HX/cgbwzAqnuQSenPdlCsFBZoPvrTP8uXh9dPSQi32WrXg+OND5T6+0AcjbwzDqFiSR+gLCrRpaUJ/SPz3v5oTbtUqnbavbt3SP6++CrVrh47t0iUURdO5cyjlUDCyplOn0H7DMOJD8nhK/SaiCf0h8emnmhdu2jTYtQuuvx46diy9/tChOh1vu3Y6M9SvfqXzuR5zjIZYtmkTSlwGGjc/bRoMHlzx92IYhpI8Qt+ggTZH+/RJtCVVGr+DdfZsXd55p4ZClsWxx4bWW7UKRdiAzsseyTnnHIqFhmEcKMkj9PXrw/nnJ9qKKo/fwfrxx+qWsRkZDaPqkzw+euOQ8Wd7AvWEdekCNewvxDCqPMnToo8R56CoKLSdkpI4W8qb4L3VqKGTe5RGUZHWD7J1K+zcGdq26f0MIzmodu21QYN0sI7/ue++suv/7neax6Uy8/zzGrPevXvovk47TTtRR46Eiy4K1T3/fPWR16sX/hxq1oTWrbWOnyrI0gcbRnJQrVr0e/bAvHlw+ulwwgnw7LMaZVIWH3yg0SeVmY8/howMXR85Elavhg8/1O21a6FJE113Dt5/X58DwB//qJkmg9SvrzM+ffQRjB4dH/sNw6hYqpXQr1qly8svhzFjYNEinbe0NHyf9d69mnK3sibF9P3qANdeqwnG5s8PlW3frkMM8vNDIl+/Ptx7b+nuHX+wk2EYVZ9q5bqJnIAqLU3FP+izD7J5swpjURHk5MTFxIMiKPTB0amRdSLrleXDNwwjeahWQu+HDvqdjKmpOsvR+vVl149cr0zs26fuGZ/OnaN3oq5cGX4P1tFqGNWHmIReRIaJyI8ikiUit5dS5yIRWSwi34vIq4HyK0Rkmfe5orwMPxiys9Un3batbvst32BLN7J+tPXKxJo1oegZf7amWFv0hmFUD/broxeRFOBx4DQgB5gnItOcc4sDdboDdwCDnXPbRKS1V94cuAdIBxww3zs2rimt+vRRfzxoHhc/NtwXuxNOKPv4lBQd2v+rX1WcjYdKzZqh++nQIdSfkJ+v+26+OVSvoMCE3jCqE7F0xh4DZDnnVgCIyGRgBLA4UOdq4HFfwJ1zP3nlZwAfOOe2esd+AAwDXisf8/fP3r0q8qecovlVTjoptK9HD3j8cdi4sfTjDztMR4guXlx6nUTTuLGmIfDnXq1ZE95+W0e1Llum5QsW6L70dI2VP/PMxNlrGEZ8iUXoOwBrAts5wKCIOj0ARORzIAWY4Jx7r5RjS2ROEZFrgGsAOpdzWkM/V/oFF4SmswtdV5N2JSNnn63LAQN0OWJE4mwxDCOxlFdnbE2gOzAEGA08IyJNYz3YOfe0cy7dOZfeqlWrcjJJ8YW+aczWGIZhJBexCP1aoFNgu6NXFiQHmOacy3fOrQSWosIfy7EVigm9YRjVnViEfh7QXUTSRKQ2cAkwLaLOVLQ1j4i0RF05K4D3gdNFpJmINANO98rihp+m3oTeMIzqyn599M65AhG5ERXoFOB559z3IjIRyHDOTSMk6IuBQuA259wWABG5F/2xAJjod8zGC79F36xZPK9qGIZReYgpBYJzbiYwM6Ls7sC6A272PpHHPg88f2hmHjzmujEMo7qT9CNjzXVjGEZ1J+mFPjdXR8P6MeaGYRjVjWoh9NaaNwyjOlMthN46Yg3DqM4ktdC/9hq8+aYJvWEY1ZukFvqPPtLl/qYLNAzDSGaSWuizs3WO2JNPTrQlhmEYiSOphX7lSptgwzAMI2mFvrBQJ8k2oTcMo7qTtEK/bp1OumETbBiGUd1JWqH3p83r0iWhZhiGYSScpBX6zZt16c8PaxiGUV1JWqG3ZGaGYRiKCb1hGEaSk7RCv22bzgnbuHGiLTEMw0gsSSv0ubnQpAnUSNo7NAzDiI2klUHLWmkYhqGY0BuGYSQ5SS30lrXSMAwjiYV+2zZr0RuGYUASC725bgzDMBQTesMwjCQnqYR+0SJo3x7WrIFdu0zoDcMwIMmE/t//hvXr4ZFHdLtDh8TaYxiGURlIKqFv316Xn3+uS8tFbxiGkWRC37KlLr/+Wpcm9IZhGEkm9AUFofUaNaBTp8TZYhiGUVlIKqHPywutd+gAtWsnzhbDMIzKQlIJ/b59oXWbQtAwDEOpmWgDyhO/RX/VVXDhhYm1xTAMo7KQVEK/bx+kpMAzzyTaEsMwjMpDUrlu8vLML28YhhFJTEIvIsNE5EcRyRKR26PsHysim0Qk0/tcFdhXGCifVp7GR7JvH9SpU5FXMAzDqHrs13UjIinA48BpQA4wT0SmOecWR1R93Tl3Y5RT/Oyc63fopu4fa9EbhmGUJJYW/TFAlnNuhXMuD5gMjKhYsw4Oa9EbhmGUJBah7wCsCWzneGWRXCAi34rIWyISHKpUV0QyRORLETkv2gVE5BqvTsamTZtitz4Ca9EbhmGUpLw6Y98BUp1zfYAPgBcD+7o459KBS4FHRaRb5MHOuaedc+nOufRWrVodtBHWojcMwyhJLEK/Fgi20Dt6ZcU457Y45/zhSs8CAwP71nrLFcBsoP8h2Fsm1qI3DMMoSSxCPw/oLiJpIlIbuAQIi54RkXaBzXOBH7zyZiJSx1tvCQwGIjtxy428PGvRG4ZhRLLfqBvnXIGI3Ai8D6QAzzvnvheRiUCGc24a8BsRORcoALYCY73DDweeEpEi9EflgSjROuXGvn3WojcMw4gkppGxzrmZwMyIsrsD63cAd0Q5bi7Q+xBtjJm8PKhfP15XMwzDqBok1chYa9EbhmGUJKmE3nz0hmEYJUkqobcWvWEYRkmSSuitRW8YhlGSpBJ6a9EbhmGUJKmE3lr0hmEYJUkqobcWvWEYRkmSSuitRW8YhlGSpBF65yzXjWEYRjSSRujz83VpLXrDMIxwkkbo93m5M61FbxiGEU7SCH1eni6tRW8YhhFO0gh9SgpcdBH06JFoSwzDMCoXMWWvrAo0bQqvv55oKwzDMCofSdOiNwzDMKJjQm8YhpHkmNAbhmEkOSb0hmEYSY4JvWEYRpJjQm8YhpHkmNAbhmEkOSb0hmEYSY445xJtQxgisglYdQinaAlsLidzyhOz68Awuw6MymoXVF7bks2uLs65VtF2VDqhP1REJMM5l55oOyIxuw4Ms+vAqKx2QeW1rTrZZa4bwzCMJMeE3jAMI8lJRqF/OtEGlILZdWCYXQdGZbULKq9t1caupPPRG4ZhGOEkY4veMAzDCGBCbxiGkeQkjdCLyDAR+VFEskTk9gTbki0ii0QkU0QyvLLmIvKBiCzzls3iZMvzIvKTiHwXKItqiyiPec/wWxEZEGe7JojIWu+5ZYrIWYF9d3h2/SgiZ1SgXZ1E5GMRWSwi34vIb73yhD6zMuxK6DMTkboi8rWILPTs+rNXniYiX3nXf11EanvldbztLG9/apztmiQiKwPPq59XHre/fe96KSLyjYhM97Yr9nk556r8B0gBlgNdgdrAQuCIBNqTDbSMKPsrcLu3fjvwYJxsOQkYAHy3P1uAs4B3AQGOBb6Ks10TgFuj1D3C+07rAGned51SQXa1AwZ4642Apd71E/rMyrAroc/Mu++G3not4CvvObwBXOKV/xsY761fD/zbW78EeL2Cnldpdk0CRkWpH7e/fe96NwOvAtO97Qp9XsnSoj8GyHLOrXDO5QGTgREJtimSEcCL3vqLwHnxuKhz7lNga4y2jABecsqXQFMRaRdHu0pjBDDZObfPObcSyEK/84qwa71zboG3vhP4AehAgp9ZGXaVRlyemXffu7zNWt7HAScDb3nlkc/Lf45vAaeIiMTRrtKI29++iHQEzgae9baFCn5eySL0HYA1ge0cyv4nqGgc8H8iMl9ErvHK2jjn1nvrG4A2iTGtTFsqw3O80Xt1fj7g3kqIXd5rcn+0NVhpnlmEXZDgZ+a5ITKBn4AP0LeHXOdcQZRrF9vl7d8OtIiHXc45/3nd7z2vR0SkTqRdUWwubx4Ffg8UedstqODnlSxCX9k4wTk3ADgTuEFETgrudPoeViniWiuTLcCTQDegH7Ae+FuiDBGRhsB/gd8553YE9yXymUWxK+HPzDlX6JzrB3RE3xp6xduGaETaJSJHAXeg9h0NNAf+EE+bRGQ48JNzbn48r5ssQr8W6BTY7uiVJQTn3Fpv+RPwNvrHv9F/FfSWPyXKvjJsSehzdM5t9P45i4BnCLka4mqXiNRCxfQV59wUrzjhzyyaXZXlmXm25AIfA8ehro+aUa5dbJe3vwmwJU52DfNcYM45tw94gfg/r8HAuSKSjbqYTwb+QQU/r2QR+nlAd6/nujbaaTEtEYaISAMRaeSvA6cD33n2XOFVuwL4XyLs8yjNlmnA5V4EwrHA9oC7osKJ8ImORJ+bb9clXgRCGtAd+LqCbBDgOeAH59zfA7sS+sxKsyvRz0xEWolIU2+9HnAa2n/wMTDKqxb5vPznOAr4yHtDioddSwI/1oL6wYPPq8K/R+fcHc65js65VFSnPnLOjaGin1d59iQn8oP2mi9F/YN/TKAdXdFoh4XA974tqF/tQ2AZMAtoHid7XkNf6fNR39+vSrMFjTh43HuGi4D0ONv1snfdb70/8HaB+n/07PoROLMC7ToBdct8C2R6n7MS/czKsCuhzwzoA3zjXf874O7A/8HXaCfwm0Adr7yut53l7e8aZ7s+8p7Xd8B/CEXmxO1vP2DjEEJRNxX6vCwFgmEYRpKTLK4b7JILNAAAADRJREFUwzAMoxRM6A3DMJIcE3rDMIwkx4TeMAwjyTGhNwzDSHJM6A3DMJIcE3rDMIwk5/8DUMf6J1oux4UAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "8aad0960-d3a1-4a71-9dcc-39027c5b3c86"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "837227e1-d554-495a-bf29-830f084c1ebe"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6020728 , 0.39792717]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "48551616-d5f9-4e27-cfc3-d764a8981835"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}